{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Function, NestedIOFunction, Variable\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.nn._functions.thnn import rnnFusedPointwise as fusedBackend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchtext.data import Field, Iterator, BucketIterator, TabularDataset\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from NMTutils import get_parser, build_data, get_model_config, evaluation\n",
    "\n",
    "from decoder import Decoder\n",
    "from encoder import Encoder\n",
    "from attention import Attention\n",
    "# others\n",
    "import argparse\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_CUDA = torch.cuda.is_available()\n",
    "DEVICE = torch.cuda.current_device()\n",
    "# USE_CUDA = False\n",
    "# DEVICE = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang1 = 'eng'\n",
    "lang2 = 'fra'\n",
    "modelcode_small = ['111301', '111311', '111301', '111311', '111311', \n",
    "                  '111311', '111311', '122421', '122521', '122621',\n",
    "                  '122622', '222421', '222521', '222421']\n",
    "modelcode_filtered = ['322521', '322421']\n",
    "\n",
    "model_idx = 14\n",
    "config, test_data, test_loader, SOURCE, TARGET = get_model_config(modelcode_small[model_idx-1], lang1, lang2,\n",
    "                                                                 device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in test_loader:\n",
    "    inputs, lengths = batch.so\n",
    "    targets = batch.ta\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build(config, SOURCE, TARGET):\n",
    "    enc = Encoder(len(SOURCE.vocab), config.EMBED, config.HIDDEN, config.NUM_HIDDEN, bidrec=True)\n",
    "    dec = Decoder(len(TARGET.vocab), config.EMBED, 2*config.HIDDEN, hidden_size2=config.HIDDEN2, \n",
    "                  sos_idx=SOURCE.vocab.stoi['<s>'], method=config.METHOD, dropout_rate=config.DROPOUT_RATE,\n",
    "                  USE_CUDA=USE_CUDA)\n",
    "    if USE_CUDA:\n",
    "        enc = enc.cuda()\n",
    "        dec = dec.cuda()\n",
    "\n",
    "    loss_function = nn.CrossEntropyLoss(ignore_index=TARGET.vocab.stoi['<pad>'])\n",
    "    return enc, dec, loss_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(model_idx, code, lang1, lang2, file_path='./data/en_fa/', file_type='small', device=-1):\n",
    "    config, test_data, test_loader, SOURCE, TARGET = get_model_config(code, lang1, lang2, device=device,\n",
    "                                                                      file_path=file_path, file_type=file_type)\n",
    "    enc, dec, loss_function = build(config, SOURCE, TARGET)\n",
    "    enc.eval()\n",
    "    dec.eval()\n",
    "    \n",
    "    enc_model_path = './data/model/{0}_{1}/{0}-{1}{2}.enc'.format(lang1, lang2, model_idx)\n",
    "    dec_model_path = './data/model/{0}_{1}/{0}-{1}{2}.dec'.format(lang1, lang2, model_idx)\n",
    "    enc.load_state_dict(torch.load(enc_model_path))\n",
    "    dec.load_state_dict(torch.load(dec_model_path))\n",
    "    return enc, dec, loss_function, test_loader, test_data, config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc, dec, loss_function, test_loader, _, config = build_model(model_idx, modelcode_small[model_idx-1], \n",
    "                                                              lang1, lang2, file_path='./data/en_fa/', \n",
    "                                                              file_type='small', device=DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beam Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/IBM/pytorch-seq2seq/blob/master/seq2seq/models/TopKDecoder.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from beam_search import Beam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dec = Decoder(len(TARGET.vocab), config.EMBED, 2*config.HIDDEN, hidden_size2=config.HIDDEN2, \\\n",
    "#                   sos_idx=SOURCE.vocab.stoi['<s>'], method=config.METHOD, USE_CUDA=USE_CUDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, V_d, m_d, n_d, sos_idx=2, num_layers=1, hidden_size2=None, decode_method='greedy',\n",
    "                 method='general', ktop=5, return_weight=True, max_len=15, dropout_rate=0.0, USE_CUDA=True):\n",
    "        super(Decoder, self).__init__()\n",
    "        \"\"\"\n",
    "        vocab_size: V_d\n",
    "        embed_size: m_d\n",
    "        hidden_size: n_d (set this value as 2*n_e)\n",
    "        methods:\n",
    "        - 'dot': dot product between hidden and encoder_outputs\n",
    "        - 'general': encoder_outputs through a linear layer \n",
    "        - 'concat': concat (hidden, encoder_outputs)\n",
    "        - 'paper': concat + tanh\n",
    "        return_weight: return attention weights\n",
    "        \"\"\"\n",
    "        self.V_d = V_d\n",
    "        self.m_d = m_d\n",
    "        self.n_d = n_d\n",
    "        self.sos_idx = sos_idx\n",
    "        self.num_layers = num_layers\n",
    "        self.return_weight = return_weight\n",
    "        self.method = method\n",
    "        self.dec_method = decode_method\n",
    "        self.ktop = ktop\n",
    "        self.use_dropout = False if dropout_rate == 0.0 else True\n",
    "        self.USE_CUDA = USE_CUDA\n",
    "        # attention\n",
    "        self.attention = Attention(hidden_size=n_d, hidden_size2=hidden_size2, method=method)\n",
    "        # embed\n",
    "        self.embed = nn.Embedding(V_d, m_d)\n",
    "        # dropout:\n",
    "        if self.use_dropout:\n",
    "            self.dropout = nn.Dropout(dropout_rate)\n",
    "        # gru(W*[embed, context] + U*[hidden_prev])\n",
    "        # gru: m+n\n",
    "        self.gru = nn.GRU(m_d+n_d, n_d, num_layers, batch_first=True, bidirectional=False)\n",
    "        # linear\n",
    "        self.linear = nn.Linear(2*n_d, V_d)\n",
    "        self.max_len = max_len\n",
    "        \n",
    "        \n",
    "    def start_token(self, batch_size):\n",
    "        sos = torch.LongTensor([self.sos_idx]*batch_size).unsqueeze(1)\n",
    "        if self.USE_CUDA: sos = sos.cuda()\n",
    "        return sos\n",
    "    \n",
    "    def forward(self, hidden, enc_outputs, enc_outputs_lengths=None, max_len=None):\n",
    "        \"\"\"\n",
    "        input:\n",
    "        - hidden(previous hidden): B, 1, n_d \n",
    "        - enc_outputs(source context): B, T_x, n_d\n",
    "        - enc_outputs_lengths: list type\n",
    "        - max_len(targer sentences max len in batch): T_y\n",
    "        \"\"\"\n",
    "        if max_len is None: max_len = self.max_len\n",
    "        \n",
    "        inputs = self.start_token(hidden.size(0)) # (B, 1)\n",
    "        embeded = self.embed(inputs) # (B, 1, m_d)\n",
    "        if self.use_dropout:\n",
    "            embeded = self.dropout(embeded)\n",
    "            \n",
    "        # prepare for whole targer sentence scores\n",
    "        scores = []\n",
    "        attn_weights = []\n",
    "\n",
    "        for i in range(max_len):\n",
    "            # context vector: previous hidden(s{i-1}), encoder_outputs(O_e) > context(c{i}), weights\n",
    "            # - context: (B, 1, n_d)\n",
    "            # - weights: (B, 1, T_x)\n",
    "            context, weights = self.attention(hidden, enc_outputs, enc_outputs_lengths, \n",
    "                                              return_weight=self.return_weight)\n",
    "            attn_weights.append(weights.squeeze(1))\n",
    "            \n",
    "            # concat context & embedding vectors: (B, 1, m_d+n_d)\n",
    "            gru_input = torch.cat([embeded, context], 2)\n",
    "            \n",
    "            # gru((context&embedding), previous hidden)\n",
    "            # output hidden(s{i}): (1, B, n_d)\n",
    "            _, hidden = self.gru(gru_input, hidden.transpose(0, 1))\n",
    "            hidden = hidden.transpose(0, 1)  # change shape to (B, 1, n_d) again\n",
    "            \n",
    "            # concat context and new hidden vectors: (B, 1, 2*n_d)\n",
    "            concated = torch.cat([hidden, context], 2)\n",
    "            \n",
    "            # get score: (B, V_d)\n",
    "            score = self.linear(concated.squeeze(1))\n",
    "            scores.append(score)\n",
    "            \n",
    "            # greedy method\n",
    "            decoded = self.decode_method(score, dec_method=self.dec_method, ktop=self.ktop)  # (B)\n",
    "            embeded = self.embed(decoded).unsqueeze(1) # next input y{i-1} (B, 1, m_d)\n",
    "            if self.use_dropout:\n",
    "                embeded = self.dropout(embeded)\n",
    "\n",
    "        # column-wise concat, reshape!! \n",
    "        # scores = [(B, V_d), (B, V_d), (B, V_d)...] > (B, V_d*max_len)\n",
    "        # attn_weights = [(B, T_x), (B, T_x), (B, T_x)...] > (B*max_len, T_x)\n",
    "        scores = torch.cat(scores, 1)\n",
    "        return scores.view(inputs.size(0)*max_len, -1), torch.cat(attn_weights)\n",
    "\n",
    "    def decode_method(self, score, dec_method='greedy', ktop=5):\n",
    "        prob, decoded = score.max(1)\n",
    "        if dec_method == 'greedy':\n",
    "            return decoded\n",
    "        elif dec_method == 'beam':\n",
    "            pass\n",
    "\n",
    "    def decode(self, hidden, enc_outputs, enc_outputs_lengths, eos_idx=3, max_len=50):\n",
    "        \n",
    "        inputs = self.start_token(hidden.size(0))  # (1, 1)\n",
    "        embeded = self.embed(inputs)  # (1, 1, m_d)\n",
    "        if self.use_dropout:\n",
    "            embeded = self.dropout(embeded)\n",
    "        \n",
    "        decodes = [] \n",
    "        attn_weights = []\n",
    "        decoded = torch.LongTensor([self.sos_idx]).view(1, -1)\n",
    "        \n",
    "        while (decoded.item() != eos_idx):\n",
    "            # context: (1, 1, n_d)\n",
    "            # weights: (1, 1, T_x)\n",
    "            context, weights = self.attention(hidden, enc_outputs, enc_outputs_lengths, \n",
    "                                              return_weight=self.return_weight)\n",
    "            attn_weights.append(weights.squeeze(1))  # (1, T_x)\n",
    "            gru_input = torch.cat([embeded, context], 2)  # (1, 1, m_d+n_d)\n",
    "            _, hidden = self.gru(gru_input, hidden.transpose(0, 1))  # (1, 1, n_d)\n",
    "            hidden = hidden.transpose(0, 1)\n",
    "            concated = torch.cat([hidden, context], 2)  # (1, 1, 2*n_d)\n",
    "            score = self.linear(concated.squeeze(1))  # (1, 2*n_d) -> # (1, V_d)\n",
    "            decoded = score.max(1)[1]  # (1)\n",
    "            decodes.append(decoded)\n",
    "            embeded = self.embed(decoded).unsqueeze(1) # (1, 1, m_d)\n",
    "            if self.use_dropout:\n",
    "                embeded = self.dropout(embeded)\n",
    "            \n",
    "            if len(decodes) >= max_len:\n",
    "                break\n",
    "        \n",
    "        return torch.cat(decodes), torch.cat(attn_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "output, hidden = enc(inputs, lengths.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Decoder' object has no attribute 'dropout'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-8a7eb51f9dc2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0membeded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0membeded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    530\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m--> 532\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Decoder' object has no attribute 'dropout'"
     ]
    }
   ],
   "source": [
    "inputs = dec.start_token(hidden.size(0))\n",
    "embeded = dec.embed(inputs)\n",
    "embeded = dec.dropout(embeded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "beam_search = Beam(5, SOURCE.vocab.stoi['<pad>'], SOURCE.vocab.stoi['<s>'], SOURCE.vocab.stoi['</s>']\n",
    "                   , n_best=1, cuda=USE_CUDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beam_search.advance(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([ 0,  0,  0,  0,  0])]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beam_search.prevKs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([ 2,  1,  1,  1,  1]), tensor([ 4854,   428,  3554,  7799,   869])]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beam_search.nextYs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "beam_idxes = defaultdict(dict)\n",
    "scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_scores, sorted_idxes = score.sort(dim=1, descending=True)\n",
    "ktop_idxes = sorted_idxes[:, :5]\n",
    "ktop_scores = sorted_scores[:, :5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.append(ktop_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "beam_idxes[1]['score'] = ktop_scores\n",
    "beam_idxes[1]['idxes'] = ktop_idxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layer Norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 5\n",
    "hidden_size = 6\n",
    "seq_len = 7\n",
    "bias = True\n",
    "B = 10\n",
    "num_layer = 2\n",
    "x = torch.randn((seq_len, B, input_size))\n",
    "h = torch.randn((num_layer*2, B, hidden_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_ih = nn.Linear(input_size, 3*hidden_size, bias=bias)\n",
    "w_hh = nn.Linear(hidden_size, 3*hidden_size, bias=bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 18]) torch.Size([10, 18])\n",
      "torch.Size([10, 6]) torch.Size([10, 6])\n"
     ]
    }
   ],
   "source": [
    "gi = w_ih(x[0])\n",
    "gh = w_hh(h[0])\n",
    "print(gi.size(), gh.size())\n",
    "i_r, i_i, i_n = gi.chunk(3, 1)\n",
    "h_r, h_i, h_n = gh.chunk(3, 1)\n",
    "\n",
    "a_r = i_r + h_r\n",
    "a_i = i_i + h_i\n",
    "print(a_r.size(), a_i.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_r = nn.LayerNorm(hidden_size, elementwise_affine=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.8483,  0.5183,  1.2515, -0.6050, -0.2809, -1.7322],\n",
       "        [ 1.1328, -0.1554, -0.1978, -0.2964, -1.7330,  1.2498],\n",
       "        [ 1.6602, -0.5964,  0.5125,  0.5637, -0.9766, -1.1634],\n",
       "        [-0.0735,  0.1378,  1.0084,  0.4167, -2.1003,  0.6110],\n",
       "        [-0.2187, -0.7102, -0.1035,  0.5517, -1.3435,  1.8242],\n",
       "        [ 0.5345,  1.8563, -0.5719, -0.5729,  0.0238, -1.2698],\n",
       "        [-0.1510, -0.0145, -0.5039,  1.1937,  1.1801, -1.7045],\n",
       "        [ 0.0017, -1.8937,  1.2953,  0.2352, -0.3739,  0.7355],\n",
       "        [ 1.0443,  0.2331,  1.0121,  0.2053, -0.6657, -1.8290],\n",
       "        [ 0.8642,  0.8665,  0.7942, -1.1174, -1.6072,  0.1996]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_r(a_r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/pytorch/pytorch/issues/4930"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import PackedSequence\n",
    "import numpy as np\n",
    "\n",
    "class LayerNormGRU(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, batch_first=False, \n",
    "                 bidirectional=False, bias=True, use_cuda=False):\n",
    "        super(LayerNormGRU, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.batch_first = batch_first\n",
    "        self.bidrectional = bidirectional\n",
    "        self.num_directions = 2 if self.bidrectional else 1\n",
    "        self.bias = bias\n",
    "        self.use_cuda = use_cuda\n",
    "        self.gate_num = 3\n",
    "        \n",
    "        self.weight_ih = nn.Linear(input_size, self.gate_num*hidden_size, bias=bias)\n",
    "        self.weight_hh = nn.Linear(hidden_size, self.gate_num*hidden_size, bias=bias)\n",
    "        if self.use_cuda:\n",
    "            self.weight_ih = self.weight_ih.cuda()\n",
    "            self.weight_hh = self.weight_hh.cuda()\n",
    "            \n",
    "        self.lm_r = nn.LayerNorm(hidden_size)\n",
    "        self.lm_i = nn.LayerNorm(hidden_size)\n",
    "        self.lm_n = nn.LayerNorm(hidden_size)\n",
    "    \n",
    "    def gru_cell(self, inpt, hidden):\n",
    "        \"\"\"\n",
    "        input:\n",
    "        * inpt: B, input_size\n",
    "        * hidden: B, hidden_size\n",
    "        output:\n",
    "        * \n",
    "        \"\"\"\n",
    "        gi = self.weight_ih(inpt)\n",
    "        gh = self.weight_hh(hidden)\n",
    "        i_r, i_i, i_n = gi.chunk(3, 1)\n",
    "        h_r, h_i, h_n = gh.chunk(3, 1)\n",
    "        \n",
    "        a_r = self.lm_r(i_r + h_r)\n",
    "        a_i = self.lm_i(i_i + h_i)\n",
    "        \n",
    "        resetgate = F.sigmoid(a_r)\n",
    "        inputgate = F.sigmoid(a_i)\n",
    "        \n",
    "        a_n = self.lm_n(i_n + resetgate * h_n)\n",
    "        newgate = F.tanh(a_n)\n",
    "        hy = newgate + inputgate * (hidden - newgate)\n",
    "        return hy\n",
    "    \n",
    "    def forward(self, inpt, hidden=None):\n",
    "        \"\"\"\n",
    "        input:\n",
    "        * inpt: seq_len, B, input_size\n",
    "        * hidden: num_layers * num_directions, B, hidden_size\n",
    "        output:\n",
    "        * output: seq_len, B, hidden_size * num_directions\n",
    "        * hidden: num_layers * num_directions, B, hidden_size\n",
    "        \"\"\"\n",
    "        is_packed = isinstance(inpt, PackedSequence)\n",
    "        if is_packed:\n",
    "            inpt, batch_sizes = inpt\n",
    "            max_batch_size = int(batch_sizes[0])\n",
    "        else:\n",
    "            batch_sizes = None\n",
    "            max_batch_size = inpt.size(0) if self.batch_first else inpt.size(1)\n",
    "        \n",
    "        if hidden is None:\n",
    "            hidden = self.init_hidden(inpt, max_batch_size)\n",
    "            \n",
    "        seq_len = inpt.size(0)\n",
    "        output_forward = []\n",
    "        for t in range(seq_len):\n",
    "            hidden = self.gru_cell(inpt[t], hidden)\n",
    "            # bidirec needed\n",
    "            output_forward.append(hidden)\n",
    "        output_forward = torch.stack(output)\n",
    "        \n",
    "        output = output_forward\n",
    "        if self.batch_first:\n",
    "            output = output.transpose(0, 1)\n",
    "        \n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self, inpt, max_batch_size):\n",
    "        hx = inpt.new_zeros(self.num_layers * self.num_directions,\n",
    "                             max_batch_size, self.hidden_size,\n",
    "                             requires_grad=False)\n",
    "        if self.use_cuda:\n",
    "            hx = hx.cuda()\n",
    "        return hx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "packed = pack_padded_sequence(x, [7]*9 + [6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "inpt, batch_sizes = packed\n",
    "max_batch_size = int(batch_sizes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([69, 5])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inpt.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "hx = inpt.new_zeros(num_layer * 2, max_batch_size, hidden_size, requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 10, 6])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hx.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "grucell = nn.GRUCell(input_size, hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "layernormgru = LayerNormGRU(input_size, hidden_size, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "hy = layernormgru.gru_cell(x[0], h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 6])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hy.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 6])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grucell(x[0], h).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (6) must match the size of tensor b (18) at non-singleton dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-133-4700aa72da4c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayernormgru\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-123-3e9cfd12e884>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inpt, hidden)\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0moutput_forward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgru_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minpt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m             \u001b[0;31m# bidirec needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0moutput_forward\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-123-3e9cfd12e884>\u001b[0m in \u001b[0;36mgru_cell\u001b[0;34m(self, inpt, hidden)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mh_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_n\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0ma_r\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlm_r\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi_r\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mh_r\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0ma_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlm_i\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi_i\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mh_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (6) must match the size of tensor b (18) at non-singleton dimension 2"
     ]
    }
   ],
   "source": [
    "out, hid = layernormgru(x.transpose(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "inpt, batch_sizes = packed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
