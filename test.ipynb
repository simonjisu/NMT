{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Function, NestedIOFunction, Variable\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.nn._functions.thnn import rnnFusedPointwise as fusedBackend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchtext.data import Field, Iterator, BucketIterator, TabularDataset\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from NMTutils import get_parser, build_data, get_model_config, evaluation\n",
    "\n",
    "from decoder import Decoder\n",
    "from encoder import Encoder\n",
    "from attention import Attention\n",
    "# others\n",
    "import argparse\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_CUDA = torch.cuda.is_available()\n",
    "DEVICE = torch.cuda.current_device()\n",
    "# USE_CUDA = False\n",
    "# DEVICE = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang1 = 'eng'\n",
    "lang2 = 'fra'\n",
    "modelcode_small = ['111301', '111311', '111301', '111311', '111311', \n",
    "                  '111311', '111311', '122421', '122521', '122621',\n",
    "                  '122622', '222421', '222521', '222421']\n",
    "modelcode_filtered = ['322521', '322421']\n",
    "\n",
    "model_idx = 14\n",
    "config, test_data, test_loader, SOURCE, TARGET = get_model_config(modelcode_small[model_idx-1], lang1, lang2,\n",
    "                                                                 device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in test_loader:\n",
    "    inputs, lengths = batch.so\n",
    "    targets = batch.ta\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build(config, SOURCE, TARGET):\n",
    "    enc = Encoder(len(SOURCE.vocab), config.EMBED, config.HIDDEN, config.NUM_HIDDEN, bidrec=True)\n",
    "    dec = Decoder(len(TARGET.vocab), config.EMBED, 2*config.HIDDEN, hidden_size2=config.HIDDEN2, \n",
    "                  sos_idx=SOURCE.vocab.stoi['<s>'], method=config.METHOD, dropout_rate=config.DROPOUT_RATE,\n",
    "                  USE_CUDA=USE_CUDA)\n",
    "    if USE_CUDA:\n",
    "        enc = enc.cuda()\n",
    "        dec = dec.cuda()\n",
    "\n",
    "    loss_function = nn.CrossEntropyLoss(ignore_index=TARGET.vocab.stoi['<pad>'])\n",
    "    return enc, dec, loss_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(model_idx, code, lang1, lang2, file_path='./data/en_fa/', file_type='small', device=-1):\n",
    "    config, test_data, test_loader, SOURCE, TARGET = get_model_config(code, lang1, lang2, device=device,\n",
    "                                                                      file_path=file_path, file_type=file_type)\n",
    "    enc, dec, loss_function = build(config, SOURCE, TARGET)\n",
    "    enc.eval()\n",
    "    dec.eval()\n",
    "    \n",
    "    enc_model_path = './data/model/{0}_{1}/{0}-{1}{2}.enc'.format(lang1, lang2, model_idx)\n",
    "    dec_model_path = './data/model/{0}_{1}/{0}-{1}{2}.dec'.format(lang1, lang2, model_idx)\n",
    "    enc.load_state_dict(torch.load(enc_model_path))\n",
    "    dec.load_state_dict(torch.load(dec_model_path))\n",
    "    return enc, dec, loss_function, test_loader, test_data, config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc, dec, loss_function, test_loader, _, config = build_model(model_idx, modelcode_small[model_idx-1], \n",
    "                                                              lang1, lang2, file_path='./data/en_fa/', \n",
    "                                                              file_type='small', device=DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beam Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/IBM/pytorch-seq2seq/blob/master/seq2seq/models/TopKDecoder.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from beam_search import Beam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dec = Decoder(len(TARGET.vocab), config.EMBED, 2*config.HIDDEN, hidden_size2=config.HIDDEN2, \\\n",
    "#                   sos_idx=SOURCE.vocab.stoi['<s>'], method=config.METHOD, USE_CUDA=USE_CUDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, V_d, m_d, n_d, sos_idx=2, num_layers=1, hidden_size2=None, decode_method='greedy',\n",
    "                 method='general', ktop=5, return_weight=True, max_len=15, dropout_rate=0.0, USE_CUDA=True):\n",
    "        super(Decoder, self).__init__()\n",
    "        \"\"\"\n",
    "        vocab_size: V_d\n",
    "        embed_size: m_d\n",
    "        hidden_size: n_d (set this value as 2*n_e)\n",
    "        methods:\n",
    "        - 'dot': dot product between hidden and encoder_outputs\n",
    "        - 'general': encoder_outputs through a linear layer \n",
    "        - 'concat': concat (hidden, encoder_outputs)\n",
    "        - 'paper': concat + tanh\n",
    "        return_weight: return attention weights\n",
    "        \"\"\"\n",
    "        self.V_d = V_d\n",
    "        self.m_d = m_d\n",
    "        self.n_d = n_d\n",
    "        self.sos_idx = sos_idx\n",
    "        self.num_layers = num_layers\n",
    "        self.return_weight = return_weight\n",
    "        self.method = method\n",
    "        self.dec_method = decode_method\n",
    "        self.ktop = ktop\n",
    "        self.use_dropout = False if dropout_rate == 0.0 else True\n",
    "        self.USE_CUDA = USE_CUDA\n",
    "        # attention\n",
    "        self.attention = Attention(hidden_size=n_d, hidden_size2=hidden_size2, method=method)\n",
    "        # embed\n",
    "        self.embed = nn.Embedding(V_d, m_d)\n",
    "        # dropout:\n",
    "        if self.use_dropout:\n",
    "            self.dropout = nn.Dropout(dropout_rate)\n",
    "        # gru(W*[embed, context] + U*[hidden_prev])\n",
    "        # gru: m+n\n",
    "        self.gru = nn.GRU(m_d+n_d, n_d, num_layers, batch_first=True, bidirectional=False)\n",
    "        # linear\n",
    "        self.linear = nn.Linear(2*n_d, V_d)\n",
    "        self.max_len = max_len\n",
    "        \n",
    "        \n",
    "    def start_token(self, batch_size):\n",
    "        sos = torch.LongTensor([self.sos_idx]*batch_size).unsqueeze(1)\n",
    "        if self.USE_CUDA: sos = sos.cuda()\n",
    "        return sos\n",
    "    \n",
    "    def forward(self, hidden, enc_outputs, enc_outputs_lengths=None, max_len=None):\n",
    "        \"\"\"\n",
    "        input:\n",
    "        - hidden(previous hidden): B, 1, n_d \n",
    "        - enc_outputs(source context): B, T_x, n_d\n",
    "        - enc_outputs_lengths: list type\n",
    "        - max_len(targer sentences max len in batch): T_y\n",
    "        \"\"\"\n",
    "        if max_len is None: max_len = self.max_len\n",
    "        \n",
    "        inputs = self.start_token(hidden.size(0)) # (B, 1)\n",
    "        embeded = self.embed(inputs) # (B, 1, m_d)\n",
    "        if self.use_dropout:\n",
    "            embeded = self.dropout(embeded)\n",
    "            \n",
    "        # prepare for whole targer sentence scores\n",
    "        scores = []\n",
    "        attn_weights = []\n",
    "\n",
    "        for i in range(max_len):\n",
    "            # context vector: previous hidden(s{i-1}), encoder_outputs(O_e) > context(c{i}), weights\n",
    "            # - context: (B, 1, n_d)\n",
    "            # - weights: (B, 1, T_x)\n",
    "            context, weights = self.attention(hidden, enc_outputs, enc_outputs_lengths, \n",
    "                                              return_weight=self.return_weight)\n",
    "            attn_weights.append(weights.squeeze(1))\n",
    "            \n",
    "            # concat context & embedding vectors: (B, 1, m_d+n_d)\n",
    "            gru_input = torch.cat([embeded, context], 2)\n",
    "            \n",
    "            # gru((context&embedding), previous hidden)\n",
    "            # output hidden(s{i}): (1, B, n_d)\n",
    "            _, hidden = self.gru(gru_input, hidden.transpose(0, 1))\n",
    "            hidden = hidden.transpose(0, 1)  # change shape to (B, 1, n_d) again\n",
    "            \n",
    "            # concat context and new hidden vectors: (B, 1, 2*n_d)\n",
    "            concated = torch.cat([hidden, context], 2)\n",
    "            \n",
    "            # get score: (B, V_d)\n",
    "            score = self.linear(concated.squeeze(1))\n",
    "            scores.append(score)\n",
    "            \n",
    "            # greedy method\n",
    "            decoded = self.decode_method(score, dec_method=self.dec_method, ktop=self.ktop)  # (B)\n",
    "            embeded = self.embed(decoded).unsqueeze(1) # next input y{i-1} (B, 1, m_d)\n",
    "            if self.use_dropout:\n",
    "                embeded = self.dropout(embeded)\n",
    "\n",
    "        # column-wise concat, reshape!! \n",
    "        # scores = [(B, V_d), (B, V_d), (B, V_d)...] > (B, V_d*max_len)\n",
    "        # attn_weights = [(B, T_x), (B, T_x), (B, T_x)...] > (B*max_len, T_x)\n",
    "        scores = torch.cat(scores, 1)\n",
    "        return scores.view(inputs.size(0)*max_len, -1), torch.cat(attn_weights)\n",
    "\n",
    "    def decode_method(self, score, dec_method='greedy', ktop=5):\n",
    "        prob, decoded = score.max(1)\n",
    "        if dec_method == 'greedy':\n",
    "            return decoded\n",
    "        elif dec_method == 'beam':\n",
    "            pass\n",
    "\n",
    "    def decode(self, hidden, enc_outputs, enc_outputs_lengths, eos_idx=3, max_len=50):\n",
    "        \n",
    "        inputs = self.start_token(hidden.size(0))  # (1, 1)\n",
    "        embeded = self.embed(inputs)  # (1, 1, m_d)\n",
    "        if self.use_dropout:\n",
    "            embeded = self.dropout(embeded)\n",
    "        \n",
    "        decodes = [] \n",
    "        attn_weights = []\n",
    "        decoded = torch.LongTensor([self.sos_idx]).view(1, -1)\n",
    "        \n",
    "        while (decoded.item() != eos_idx):\n",
    "            # context: (1, 1, n_d)\n",
    "            # weights: (1, 1, T_x)\n",
    "            context, weights = self.attention(hidden, enc_outputs, enc_outputs_lengths, \n",
    "                                              return_weight=self.return_weight)\n",
    "            attn_weights.append(weights.squeeze(1))  # (1, T_x)\n",
    "            gru_input = torch.cat([embeded, context], 2)  # (1, 1, m_d+n_d)\n",
    "            _, hidden = self.gru(gru_input, hidden.transpose(0, 1))  # (1, 1, n_d)\n",
    "            hidden = hidden.transpose(0, 1)\n",
    "            concated = torch.cat([hidden, context], 2)  # (1, 1, 2*n_d)\n",
    "            score = self.linear(concated.squeeze(1))  # (1, 2*n_d) -> # (1, V_d)\n",
    "            decoded = score.max(1)[1]  # (1)\n",
    "            decodes.append(decoded)\n",
    "            embeded = self.embed(decoded).unsqueeze(1) # (1, 1, m_d)\n",
    "            if self.use_dropout:\n",
    "                embeded = self.dropout(embeded)\n",
    "            \n",
    "            if len(decodes) >= max_len:\n",
    "                break\n",
    "        \n",
    "        return torch.cat(decodes), torch.cat(attn_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "output, hidden = enc(inputs, lengths.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Decoder' object has no attribute 'dropout'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-8a7eb51f9dc2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0membeded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0membeded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    530\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m--> 532\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Decoder' object has no attribute 'dropout'"
     ]
    }
   ],
   "source": [
    "inputs = dec.start_token(hidden.size(0))\n",
    "embeded = dec.embed(inputs)\n",
    "embeded = dec.dropout(embeded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "beam_search = Beam(5, SOURCE.vocab.stoi['<pad>'], SOURCE.vocab.stoi['<s>'], SOURCE.vocab.stoi['</s>']\n",
    "                   , n_best=1, cuda=USE_CUDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beam_search.advance(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([ 0,  0,  0,  0,  0])]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beam_search.prevKs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([ 2,  1,  1,  1,  1]), tensor([ 4854,   428,  3554,  7799,   869])]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beam_search.nextYs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "beam_idxes = defaultdict(dict)\n",
    "scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_scores, sorted_idxes = score.sort(dim=1, descending=True)\n",
    "ktop_idxes = sorted_idxes[:, :5]\n",
    "ktop_scores = sorted_scores[:, :5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.append(ktop_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "beam_idxes[1]['score'] = ktop_scores\n",
    "beam_idxes[1]['idxes'] = ktop_idxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layer Norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/pytorch/pytorch/issues/4930"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import PackedSequence\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from itertools import accumulate\n",
    "\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNormGRU(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, batch_first=False, layernorm=False,\n",
    "                 bidirectional=False, bias=True, use_cuda=False, return_all_hidden=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            : input_size: The number of expected features in the input `x`\n",
    "            : hidden_size: The number of features in the hidden state `h`\n",
    "            : num_layers: Number of recurrent layers.\n",
    "            : batch_first: If ``True``, then the input and output tensors are provided as `(batch, seq, feature)`\n",
    "            : layernorm: If ``True``, then use torch.nn.Layernorm to normalize linear output in gru\n",
    "            : bidirectional: If ``True``, becomes a bidirectional RNN. Default: ``False``\n",
    "            : bias: If ``False``, then the layer does not use bias weights `b_ih` and `b_hh`. Default: ``True``\n",
    "            : use_cuda: If ``True``, then use cuda to init hidden state. (didn't figure out how to auto detect it, yet) Default: ``False``\n",
    "            : return_all_hidden: If ``True``, return all hidden layers output. Default: ``False``\n",
    "\n",
    "        Input:\n",
    "            : inputs: tensor(seq_len, batch_size, input_size) // 'tensor(sum(batch_sizes), input_size)'\n",
    "            : hidden: tensor(num_layers * num_directions, batch_size, hidden_size) if nothing then auto initialize as zeros\n",
    "\n",
    "            output:\n",
    "            : output: tensor(seq_len, batch_size, hidden_size * num_directions) // tensor(sum(batch_sizes), hidden_size * num_directions)\n",
    "            : hidden: tensor(num_layers * num_directions, B, hidden_size)\n",
    "\n",
    "        \"\"\"\n",
    "        super(LayerNormGRU, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.layernorm = layernorm\n",
    "        self.batch_first = batch_first\n",
    "        self.bidrectional = bidirectional\n",
    "        self.use_cuda = use_cuda\n",
    "        self.return_all_hidden = return_all_hidden\n",
    "        self.num_directions = 2 if self.bidrectional else 1\n",
    "        self.bias = bias\n",
    "        self.gate_num = 3\n",
    "\n",
    "    def forward(self, inputs, hidden=None):\n",
    "        \"\"\"\n",
    "        [no packed size // packed size]\n",
    "        input:\n",
    "        * inputs: tensor(seq_len, batch_size, input_size) // 'tensor(sum(batch_sizes), input_size)'\n",
    "        * hidden: tensor(num_layers * num_directions, batch_size, hidden_size) if nothing then auto initialize as zeros\n",
    "        output:\n",
    "        * output: tensor(seq_len, batch_size, hidden_size * num_directions) // tensor(sum(batch_sizes), hidden_size * num_directions)\n",
    "        * hidden: tensor(num_layers * num_directions, B, hidden_size)\n",
    "        \"\"\"\n",
    "        is_packed = isinstance(inputs, PackedSequence)\n",
    "        if is_packed:\n",
    "            inputs, batch_sizes = inputs\n",
    "            max_batch_size = int(batch_sizes[0])\n",
    "        else:\n",
    "            batch_sizes = None\n",
    "            max_batch_size = inputs.size(0) if self.batch_first else inputs.size(1)\n",
    "\n",
    "        if hidden is None:\n",
    "            hidden = self.init_hidden(max_batch_size)\n",
    "\n",
    "        self.func = StackedGRU(input_size=self.input_size,\n",
    "                               hidden_size=self.hidden_size,\n",
    "                               num_layers=self.num_layers,\n",
    "                               bidirectional=self.bidrectional,\n",
    "                               layernorm=self.layernorm,\n",
    "                               return_all_hidden=self.return_all_hidden,\n",
    "                               is_packed=is_packed)\n",
    "        if self.batch_first and not is_packed:\n",
    "            inputs = inputs.transpose(0, 1)  # B, T, D --> T, B, D\n",
    "\n",
    "        output, hidden = self.func(inputs, hidden, batch_sizes=batch_sizes)\n",
    "\n",
    "        if self.batch_first and not is_packed:\n",
    "            output = output.transpose(0, 1)\n",
    "        if is_packed:\n",
    "            output = PackedSequence(output, batch_sizes)\n",
    "\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self, max_batch_size):\n",
    "        hx = torch.zeros(self.num_layers * self.num_directions, max_batch_size, self.hidden_size,\n",
    "                            requires_grad=False)\n",
    "        if self.use_cuda:\n",
    "            hx = hx.cuda()\n",
    "        return hx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StackedGRU(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, num_layers, bidirectional=False, layernorm=False, \n",
    "                 return_all_hidden=False, batch_first=False, is_packed=False):\n",
    "        super(StackedGRU, self).__init__()\n",
    "        # to do: add is_packed\n",
    "        self.batch_first = batch_first\n",
    "        self.layernorm = layernorm\n",
    "        self.bidirec = bidirectional\n",
    "        self.return_all_hidden = return_all_hidden\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_directions = 2 if self.bidirec else 1\n",
    "        self.num_layers = num_layers\n",
    "        self.build_layers(input_size, hidden_size)\n",
    "        # packed seq\n",
    "        self.is_packed = is_packed\n",
    "        \n",
    "    def build_layers(self, input_size, hidden_size):\n",
    "        self.layers = self.create_layers(input_size, hidden_size)\n",
    "        if self.bidirec:\n",
    "            self.r_layers = self.create_layers(input_size, hidden_size)\n",
    "    \n",
    "    def create_layers(self, input_size, hidden_size):\n",
    "        layers = nn.ModuleList()\n",
    "        for _ in range(self.num_layers):\n",
    "            layers.append(GRUCell(input_size, hidden_size, layernorm=self.layernorm))\n",
    "            input_size = hidden_size\n",
    "        return layers\n",
    "        \n",
    "    def forward(self, inputs, hidden, batch_sizes=None):\n",
    "        \"\"\"\n",
    "        * input:\n",
    "        inputs: 'tensor(T, B, D)' if packed, 'tensor(sum(batch_sizes), D)'\n",
    "        hidden: 'tensor(num_layers * num_directions, B, H)'\n",
    "        \n",
    "        * return:\n",
    "        output: 'tensor(T, B, num_directions*H)' // tensor(sum(batch_sizes), H)\n",
    "                 if return_all_hiddens \n",
    "                 - 'tensor(num_layers, T, B, num_directions*H)' // 'tensor(num_layers, sum(batch_sizes), H)' \n",
    "        hidden 'tensor(num_layers*num_directions, B, H)'\n",
    "        \"\"\"\n",
    "        if self.bidirec:\n",
    "            # output (num_layers, T, B, 2H)\n",
    "            # last_hidden (num_layers*num_directions, B, H)\n",
    "            # forward: idx of time t ~ (0, 1, ..., T-1)            \n",
    "            f_idx = [i for i in range(self.num_layers * self.num_directions) if i % 2 == 0]\n",
    "            f_all_outputs, f_last_hidden = self._forward(self.layers, inputs, hidden[f_idx, :], batch_sizes)\n",
    "            \n",
    "            # backward: \n",
    "            r_inputs = self._flip(inputs, 0)  # (T, B, H) idx of time t ~ (T-1, ... , 0)\n",
    "            b_idx = [i for i in range(self.num_layers * self.num_directions) if i % 2 != 0]\n",
    "            b_all_outputs, b_last_hidden = self._forward(self.r_layers, r_inputs, hidden[b_idx, :], batch_sizes)\n",
    "            b_all_outputs = self._flip(b_all_outputs, 1) # (num_layers, T, B, H) idx of time t ~ (0, 1, ..., T-1)\n",
    "            # concate layers\n",
    "            # f: hidden[T-1], b: hidden[0]\n",
    "            output = torch.cat([f_all_outputs, b_all_outputs], -1)\n",
    "            idx = [int(i/self.num_directions) if i % 2 == 0 else \\\n",
    "                   i + int(((self.num_layers * self.num_directions) - i) / 2) \\\n",
    "                   for i in range(self.num_layers * self.num_directions) ]\n",
    "            hidden = torch.cat([f_last_hidden, b_last_hidden])[idx, :]\n",
    "\n",
    "            if self.return_all_hidden:\n",
    "                return output, hidden\n",
    "            return output[-1], hidden\n",
    "            \n",
    "        else:\n",
    "            f_all_outputs, f_last_hidden = self._forward(self.layers, inputs, hidden, batch_sizes)\n",
    "            if self.return_all_hidden:\n",
    "                return f_all_outputs, f_last_hidden\n",
    "            return f_all_outputs[-1], f_last_hidden\n",
    "\n",
    "    def _forward(self, layers, inputs, hidden, batch_sizes=None):\n",
    "        \"\"\"\n",
    "        * input:\n",
    "        layers: nn.ModuleList for one direction layers\n",
    "        inp: tensor(T, B, D) // tensor(sum(batch_sizes), D)\n",
    "        hid: num_layers, B, H (init hidden)\n",
    "        \n",
    "        * return:\n",
    "        all_outputs: all layers a forward or backward layer\n",
    "        tensor(num_layers, T, B, H) // tensor(num_layers, sum(batch_sizes), H)\n",
    "        last_hidden: \n",
    "        tensor(num_layers, B, H)\n",
    "        \"\"\"\n",
    "        # todo: add is_packed\n",
    "        assert isinstance(layers, nn.ModuleList)\n",
    "        if self.is_packed:\n",
    "            assert batch_sizes is not None, 'packed sequence must have list of batch_sizes'\n",
    "            acc_bs = [0] + list(accumulate(batch_sizes.tolist())) \n",
    "        # all_outputs\n",
    "        # if packed: num_layers, sum(batch_sizes), H\n",
    "        # if not packed : num_layers, T, B, H\n",
    "        all_outputs = []\n",
    "        for l_idx, layer in enumerate(layers):\n",
    "            hid = hidden.chunk(self.num_layers, 0)[l_idx].squeeze(0)  # init hidden: 1, B, H --> B, H\n",
    "            output_ith_layer = []\n",
    "            \n",
    "            if self.is_packed:\n",
    "                # packed\n",
    "                for t in range(len(batch_sizes)): # input: acc_bs[t:(t+1)]\n",
    "                    hid = layer(inputs[acc_bs[t]:acc_bs[t+1]], hid[:batch_sizes[t]])\n",
    "                    output_ith_layer.append(hid) \n",
    "                output_ith_layer = torch.cat(output_ith_layer, 0) # sum(batch_sizes), H \n",
    "            else:\n",
    "                # not packed\n",
    "                for t in range(inputs.size(0)):\n",
    "                    hid = layer(inputs[t], hid)\n",
    "                    output_ith_layer.append(hid)    \n",
    "                output_ith_layer = torch.stack(output_ith_layer)  # T, B, H \n",
    "            \n",
    "            inputs = output_ith_layer \n",
    "            all_outputs.append(output_ith_layer)\n",
    "        all_outputs = torch.stack(all_outputs)\n",
    "        if self.is_packed:\n",
    "            last_idx = self.get_last_idx(all_outputs.size(1), batch_sizes, acc_bs)\n",
    "            last_hidden = torch.stack([out[last_idx] for out in all_outputs]) # num_layer, max_batch_size, H\n",
    "        else:\n",
    "            last_hidden = torch.stack([out[-1] for out in all_outputs]) # num_layer, B, H\n",
    "        \n",
    "        return all_outputs, last_hidden\n",
    "    \n",
    "    def get_last_idx(self, total_len, batch_sizes, acc_bs):\n",
    "        batch_sizes = batch_sizes if isinstance(batch_sizes, list) else batch_sizes.tolist()\n",
    "        mask = batch_sizes + [0]\n",
    "        mask = [mask[i+1] - mask[i] for i in range(len(batch_sizes))]\n",
    "        temp = list(range(total_len))\n",
    "        result = []\n",
    "        for i, m in enumerate(mask):\n",
    "            if m != 0:\n",
    "                result.extend(temp[acc_bs[i]:acc_bs[i+1]][m:])\n",
    "        return list(reversed(result))\n",
    "    \n",
    "    \n",
    "    def _flip(self, x, dim):\n",
    "        \"\"\"\n",
    "        https://discuss.pytorch.org/t/optimizing-diagonal-stripe-code/17777/16\n",
    "        \"\"\"\n",
    "        indices = [slice(None)] * x.dim()\n",
    "        indices[dim] = torch.arange(x.size(dim) - 1, -1, -1,\n",
    "                                    dtype=torch.long, device=x.device)\n",
    "        return x[tuple(indices)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUCell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, bias=True, layernorm=False, gate_num=3):\n",
    "        super(GRUCell, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.bias = bias\n",
    "        self.hidden_size = hidden_size\n",
    "        self.layernorm = layernorm\n",
    "        self.gate_num = gate_num\n",
    "        \n",
    "        self.weight_ih = nn.Linear(input_size, gate_num*hidden_size, bias=bias)\n",
    "        self.weight_hh = nn.Linear(hidden_size, gate_num*hidden_size, bias=bias)\n",
    "        if self.layernorm:\n",
    "            self.lm_r = nn.LayerNorm(hidden_size)\n",
    "            self.lm_i = nn.LayerNorm(hidden_size)\n",
    "            self.lm_n = nn.LayerNorm(hidden_size)\n",
    "        \n",
    "    def forward(self, inputs, hidden):\n",
    "        \"\"\"\n",
    "        inputs:\n",
    "        * inputs: B, input_size\n",
    "        * hidden: B, hidden_size\n",
    "        output:\n",
    "        * hy: B, hidden_size\n",
    "        \"\"\"\n",
    "        gi = self.weight_ih(inputs)\n",
    "        gh = self.weight_hh(hidden)\n",
    "        i_r, i_i, i_n = gi.chunk(3, 1)\n",
    "        h_r, h_i, h_n = gh.chunk(3, 1)\n",
    "        \n",
    "        a_r = i_r + h_r\n",
    "        a_i = i_i + h_i\n",
    "        if self.layernorm:\n",
    "            a_r = self.lm_r(a_r)\n",
    "            a_i = self.lm_i(a_i)\n",
    "            \n",
    "        resetgate = F.sigmoid(a_r)\n",
    "        inputgate = F.sigmoid(a_i)\n",
    "        \n",
    "        a_n = i_n + resetgate * h_n\n",
    "        if self.layernorm:\n",
    "            a_n = self.lm_n(a_n)\n",
    "            \n",
    "        newgate = F.tanh(a_n)\n",
    "        hy = newgate + inputgate * (hidden - newgate)\n",
    "        return hy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packed sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = 10  # vocab length\n",
    "T = 6  # max sequence length\n",
    "\n",
    "# batch_first!! B, T\n",
    "input_seq = torch.LongTensor([[9, 8, 4, 2, 0, 0],\n",
    "                              [4, 6, 1, 1, 0, 0],\n",
    "                              [8, 7, 5, 0, 0, 0],\n",
    "                              [4, 1, 0, 0, 0, 0],\n",
    "                              [4, 6, 8, 1, 9, 2]])\n",
    "\n",
    "# decreasing order\n",
    "input_lengths = torch.LongTensor([torch.max(input_seq[i, :].data.nonzero())+1 for i in range(input_seq.size(0))])\n",
    "input_lengths, sorted_idx = input_lengths.sort(0, descending=True)\n",
    "input_seq = input_seq[sorted_idx]\n",
    "\n",
    "# pack sequences\n",
    "# packed_input = pack_padded_sequence(input_seq, input_lengths.tolist(), batch_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input seqence 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 9,  8,  4,  2,  0,  0],\n",
       "        [ 4,  6,  1,  1,  0,  0],\n",
       "        [ 8,  7,  5,  0,  0,  0],\n",
       "        [ 4,  1,  0,  0,  0,  0],\n",
       "        [ 4,  6,  8,  1,  9,  2]])"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4,  6,  8,  1,  9,  2],\n",
       "        [ 9,  8,  4,  2,  0,  0],\n",
       "        [ 4,  6,  1,  1,  0,  0],\n",
       "        [ 8,  7,  5,  0,  0,  0],\n",
       "        [ 4,  1,  0,  0,  0,  0]])"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_seq[sorted_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 6, 7])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed = nn.Embedding(V, 7)\n",
    "embeded = embed(input_seq)\n",
    "embeded.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "packed_input = pack_padded_sequence(embeded, input_lengths.tolist(), batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([19, 7]), [5, 5, 4, 3, 1, 1])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "packed_input[0].size(), packed_input[1].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru = nn.GRU(input_size=7, hidden_size=2, num_layers=1, bidirectional=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pack 한것과 안한것 차이 seq_len 이 다름 max len으로 되어있음\n",
    "# https://discuss.pytorch.org/t/lstm-hidden-cell-outputs-and-packed-sequence-for-variable-length-sequence-inputs/1183\n",
    "nopack_o, nopack_h = gru(embeded)\n",
    "pack_o, pack_h = gru(packed_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 6, 4]),\n",
       " torch.Size([19, 4]),\n",
       " torch.Size([2, 6, 2]),\n",
       " torch.Size([2, 5, 2]))"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nopack_o.size(), pack_o[0].size(), nopack_h.size(), pack_h.size() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0206, -0.3060,  0.7552, -0.5244],\n",
       "         [ 0.1811,  0.1301,  0.9484, -0.5482],\n",
       "         [-0.0503, -0.1805,  0.8293,  0.0213],\n",
       "         [-0.3703, -0.0457,  0.8630,  0.0969],\n",
       "         [ 0.3921, -0.1847,  0.7820, -0.0545],\n",
       "         [-0.2316, -0.0441,  0.9626,  0.2920]],\n",
       "\n",
       "        [[ 0.4251, -0.4135,  0.8408, -0.3390],\n",
       "         [-0.0511, -0.0747,  0.9452, -0.1381],\n",
       "         [-0.0222, -0.4134,  0.4404, -0.0956],\n",
       "         [-0.4067, -0.0922,  0.9615,  0.2548],\n",
       "         [ 0.0316, -0.2260,  0.5681,  0.0943],\n",
       "         [-0.2319, -0.1229,  0.5681,  0.0943]],\n",
       "\n",
       "        [[ 0.0877, -0.5331,  0.7641, -0.3096],\n",
       "         [ 0.2005,  0.0903,  0.8415, -0.5562],\n",
       "         [-0.3886, -0.3916, -0.1171,  0.1611],\n",
       "         [-0.5180, -0.1251,  0.5126, -0.0278],\n",
       "         [-0.1032, -0.2695,  0.5352,  0.0812],\n",
       "         [-0.2282, -0.1882,  0.5352,  0.0812]],\n",
       "\n",
       "        [[ 0.0196, -0.5854,  0.8491, -0.0361],\n",
       "         [ 0.5294, -0.1875,  0.5783, -0.1855],\n",
       "         [ 0.2926, -0.4325, -0.3916,  0.2826],\n",
       "         [-0.3823, -0.1987,  0.4650,  0.0618],\n",
       "         [-0.1605, -0.3098,  0.4650,  0.0618],\n",
       "         [-0.2230, -0.2430,  0.4650,  0.0618]],\n",
       "\n",
       "        [[ 0.0239, -0.6757,  0.4878, -0.2329],\n",
       "         [-0.2533, -0.1960,  0.1914, -0.0653],\n",
       "         [-0.0054, -0.4493,  0.3150,  0.0345],\n",
       "         [-0.3013, -0.2556,  0.3150,  0.0345],\n",
       "         [-0.1848, -0.3458,  0.3150,  0.0345],\n",
       "         [-0.2176, -0.2894,  0.3150,  0.0345]]])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nopack_o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0239, -0.6757],\n",
       "         [-0.2533, -0.1960],\n",
       "         [-0.0054, -0.4493],\n",
       "         [-0.3013, -0.2556],\n",
       "         [-0.1848, -0.3458],\n",
       "         [-0.2176, -0.2894]],\n",
       "\n",
       "        [[ 0.7552, -0.5244],\n",
       "         [ 0.9484, -0.5482],\n",
       "         [ 0.8293,  0.0213],\n",
       "         [ 0.8630,  0.0969],\n",
       "         [ 0.7820, -0.0545],\n",
       "         [ 0.9626,  0.2920]]])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nopack_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PackedSequence(data=tensor([[-0.0206, -0.3060,  0.7859, -0.6231],\n",
       "        [ 0.3921, -0.1847,  0.8851, -0.1073],\n",
       "        [-0.0206, -0.3060,  0.7315, -0.6472],\n",
       "        [-0.0503, -0.1805,  0.7934,  0.0918],\n",
       "        [-0.0206, -0.3060,  0.5457, -0.2945],\n",
       "        [ 0.2378, -0.0514,  0.9414, -0.4815],\n",
       "        [-0.0174, -0.2925,  0.9278,  0.0331],\n",
       "        [ 0.2378, -0.0514,  0.7760, -0.5244],\n",
       "        [ 0.5332, -0.3803,  0.3400,  0.0630],\n",
       "        [-0.3859, -0.2990,  0.1914, -0.0653],\n",
       "        [-0.0311, -0.1999,  0.9258,  0.0557],\n",
       "        [-0.0054, -0.4792,  0.8096, -0.0991],\n",
       "        [-0.3045, -0.0834,  0.3291, -0.1149],\n",
       "        [ 0.6439, -0.4076, -0.5722,  0.2439],\n",
       "        [-0.3863, -0.2093,  0.8071, -0.0447],\n",
       "        [-0.2406, -0.4790,  0.9393,  0.2513],\n",
       "        [-0.4781, -0.1169,  0.1914, -0.0653],\n",
       "        [ 0.2912, -0.3629,  0.8907,  0.0489],\n",
       "        [-0.1373, -0.3698,  0.9393,  0.2513]]), batch_sizes=tensor([ 5,  5,  4,  3,  1,  1]))"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pack_o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1373, -0.3698],\n",
       "         [-0.2406, -0.4790],\n",
       "         [-0.4781, -0.1169],\n",
       "         [ 0.6439, -0.4076],\n",
       "         [-0.3859, -0.2990]],\n",
       "\n",
       "        [[ 0.7859, -0.6231],\n",
       "         [ 0.8851, -0.1073],\n",
       "         [ 0.7315, -0.6472],\n",
       "         [ 0.7934,  0.0918],\n",
       "         [ 0.5457, -0.2945]]])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pack_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "packed, batch_sizes = pack_padded_sequence(embeded, input_lengths.tolist(), batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "unpacked, unpacked_len = pad_packed_sequence(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4]\n",
      "[5, 6, 7, 8, 9]\n",
      "[10, 11, 12, 13]\n",
      "[14, 15, 16]\n",
      "[17, 18]\n",
      "[19]\n"
     ]
    }
   ],
   "source": [
    "a = list(range(20))\n",
    "print(a[0:5])\n",
    "print(a[5:10])\n",
    "print(a[10:14])\n",
    "print(a[14:17])\n",
    "print(a[17:19])\n",
    "print(a[19:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import accumulate, islice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sizes = [5, 5, 4, 3, 1, 1]\n",
    "total_len = 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = get_last_idx(total_len, batch_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4422, -0.0451],\n",
       "        [ 0.6043, -0.4460],\n",
       "        [-0.3532,  0.0088],\n",
       "        [ 0.4450, -0.5224],\n",
       "        [ 0.6037, -0.1997]])"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pack_o[0][result]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.4422, -0.0451],\n",
       "         [-0.3532,  0.0088],\n",
       "         [ 0.6043, -0.4460],\n",
       "         [ 0.4450, -0.5224],\n",
       "         [ 0.6037, -0.1997]]])"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pack_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_idx(total_len, batch_sizes):\n",
    "    # a: acc_of a\n",
    "    # b: len of batch\n",
    "    assert isinstance(batch_sizes, list)\n",
    "    mask = batch_sizes + [0]\n",
    "    mask = [mask[i+1] - mask[i] for i in range(len(batch_sizes))]\n",
    "    acc_bs = [0] + list(accumulate(batch_sizes))\n",
    "    temp = list(range(total_len))\n",
    "    result = []\n",
    "    for i, m in enumerate(mask):\n",
    "        if m != 0:\n",
    "            result.extend(temp[acc_bs[i]:acc_bs[i+1]][m:])\n",
    "    return list(reversed(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_GRU = StackedGRU(input_size=7, hidden_size=2, num_layers=3, bidirectional=True, batch_first=False, \n",
    "                         is_packed=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 5, 2])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden = embeded.new_zeros(3 * 2, embeded.size(0), 2, requires_grad=False)\n",
    "hidden.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "packed, batch_sizes = packed_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "nopack_o, nopack_h = stacked_GRU.forward(embeded.transpose(0, 1), hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_GRU = StackedGRU(input_size=7, hidden_size=2, num_layers=3, bidirectional=True, batch_first=False, \n",
    "                         is_packed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "pack_o, pack_h = stacked_GRU(packed, hidden, batch_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "hid = hidden.chunk(stacked_GRU.num_layers, 0)[0].squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([6, 5, 4]),\n",
       " torch.Size([6, 5, 2]),\n",
       " torch.Size([19, 4]),\n",
       " torch.Size([6, 5, 2]))"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nopack_o.size(), nopack_h.size(), pack_o.size(), pack_h.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1057,  0.2791,  0.2545, -0.3794],\n",
       "        [-0.1027,  0.2818,  0.3091, -0.3687],\n",
       "        [-0.1057,  0.2791,  0.2597, -0.3865],\n",
       "        [-0.0949,  0.2896,  0.3566, -0.3696],\n",
       "        [-0.1057,  0.2791,  0.3667, -0.3633],\n",
       "        [-0.1294,  0.3859,  0.3948, -0.3636],\n",
       "        [-0.1241,  0.3906,  0.3158, -0.3717],\n",
       "        [-0.1294,  0.3859,  0.3890, -0.3648],\n",
       "        [-0.1215,  0.3928,  0.4252, -0.3616],\n",
       "        [-0.1310,  0.3835,  0.3946, -0.3464],\n",
       "        [-0.1223,  0.4304,  0.3714, -0.3411],\n",
       "        [-0.1237,  0.4308,  0.3453, -0.3424],\n",
       "        [-0.1230,  0.4286,  0.3579, -0.3406],\n",
       "        [-0.1208,  0.4321,  0.4154, -0.3424],\n",
       "        [-0.1049,  0.4541,  0.2971, -0.2558],\n",
       "        [-0.1130,  0.4504,  0.2953, -0.2538],\n",
       "        [-0.1062,  0.4522,  0.2971, -0.2558],\n",
       "        [-0.0895,  0.4694,  0.2697, -0.2496],\n",
       "        [-0.0738,  0.4810,  0.2953, -0.2538]])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pack_o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0738,  0.4810,  0.2545, -0.3794],\n",
       "        [-0.1062,  0.4522,  0.2597, -0.3865],\n",
       "        [-0.1130,  0.4504,  0.3566, -0.3696],\n",
       "        [-0.1208,  0.4321,  0.3948, -0.3636],\n",
       "        [-0.1310,  0.3835,  0.3946, -0.3464]])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([h for h in pack_h[-2:]], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input torch.Size([5, 7])\n",
      "hidden tensor([[ 0.,  0.],\n",
      "        [ 0.,  0.],\n",
      "        [ 0.,  0.],\n",
      "        [ 0.,  0.],\n",
      "        [ 0.,  0.]])\n",
      "torch.Size([5, 2])\n",
      "input torch.Size([5, 7])\n",
      "hidden tensor([[ 0.0244,  0.3408],\n",
      "        [ 0.1301,  0.0093],\n",
      "        [ 0.0244,  0.3408],\n",
      "        [ 0.3196, -0.0357],\n",
      "        [ 0.0244,  0.3408]])\n",
      "torch.Size([5, 2])\n",
      "input torch.Size([4, 7])\n",
      "hidden tensor([[-0.3063,  0.4356],\n",
      "        [ 0.3605, -0.0202],\n",
      "        [-0.3063,  0.4356],\n",
      "        [ 0.3636, -0.1822]])\n",
      "torch.Size([4, 2])\n",
      "input torch.Size([3, 7])\n",
      "hidden tensor([[ 0.1719,  0.1572],\n",
      "        [ 0.2532,  0.2940],\n",
      "        [ 0.2218, -0.0176]])\n",
      "torch.Size([3, 2])\n",
      "input torch.Size([1, 7])\n",
      "hidden tensor([[ 0.5032, -0.0707]])\n",
      "torch.Size([1, 2])\n",
      "input torch.Size([1, 7])\n",
      "hidden tensor([[ 0.3811, -0.0112]])\n",
      "torch.Size([1, 2])\n"
     ]
    }
   ],
   "source": [
    "all_output=[]\n",
    "for t in range(len(batch_sizes)):\n",
    "    print('input',packed[acc_bs[t]:acc_bs[t+1]].size())\n",
    "    print('hidden', hid[:batch_sizes[t]])\n",
    "    hid = stacked_GRU.layers[0](packed[acc_bs[t]:acc_bs[t+1]], hid[:batch_sizes[t]])\n",
    "    all_output.append(hid)\n",
    "    print(hid.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test for layernorm gru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 4,  6,  8,  1,  9,  2],\n",
       "         [ 9,  8,  4,  2,  0,  0],\n",
       "         [ 4,  6,  1,  1,  0,  0],\n",
       "         [ 8,  7,  5,  0,  0,  0],\n",
       "         [ 4,  1,  0,  0,  0,  0]]), tensor([ 6,  4,  4,  3,  2]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_seq, input_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 6, 7])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed = nn.Embedding(V, 7)\n",
    "embeded = embed(input_seq)\n",
    "embeded.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru = LayerNormGRU(input_size=7, hidden_size=3, num_layers=2, bidirectional=True, batch_first=True, \n",
    "                   layernorm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "packed_input = pack_padded_sequence(embeded, input_lengths.tolist(), batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nopack_o, nopack_h = gru(embeded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 6, 6]), torch.Size([4, 5, 3]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nopack_o.size(), nopack_h.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pack_o, pack_h = gru(packed_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([19, 6]), torch.Size([4, 5, 3]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pack_o[0].size(), pack_h.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "unpack_o, unpack_len = pad_packed_sequence(pack_o, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 6, 6]), tensor([ 6,  4,  4,  3,  2]))"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unpack_o.size(), unpack_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
