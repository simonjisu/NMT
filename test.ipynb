{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Function, NestedIOFunction, Variable\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.nn._functions.thnn import rnnFusedPointwise as fusedBackend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchtext.data import Field, Iterator, BucketIterator, TabularDataset\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from NMTutils import get_parser, build_data, get_model_config, evaluation\n",
    "\n",
    "from decoder import Decoder\n",
    "from encoder import Encoder\n",
    "from attention import Attention\n",
    "# others\n",
    "import argparse\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_CUDA = torch.cuda.is_available()\n",
    "DEVICE = torch.cuda.current_device()\n",
    "# USE_CUDA = False\n",
    "# DEVICE = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang1 = 'eng'\n",
    "lang2 = 'fra'\n",
    "modelcode_small = ['111301', '111311', '111301', '111311', '111311', \n",
    "                  '111311', '111311', '122421', '122521', '122621',\n",
    "                  '122622', '222421', '222521', '222421']\n",
    "modelcode_filtered = ['322521', '322421']\n",
    "\n",
    "model_idx = 14\n",
    "config, test_data, test_loader, SOURCE, TARGET = get_model_config(modelcode_small[model_idx-1], lang1, lang2,\n",
    "                                                                 device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in test_loader:\n",
    "    inputs, lengths = batch.so\n",
    "    targets = batch.ta\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build(config, SOURCE, TARGET):\n",
    "    enc = Encoder(len(SOURCE.vocab), config.EMBED, config.HIDDEN, config.NUM_HIDDEN, bidrec=True)\n",
    "    dec = Decoder(len(TARGET.vocab), config.EMBED, 2*config.HIDDEN, hidden_size2=config.HIDDEN2, \n",
    "                  sos_idx=SOURCE.vocab.stoi['<s>'], method=config.METHOD, dropout_rate=config.DROPOUT_RATE,\n",
    "                  USE_CUDA=USE_CUDA)\n",
    "    if USE_CUDA:\n",
    "        enc = enc.cuda()\n",
    "        dec = dec.cuda()\n",
    "\n",
    "    loss_function = nn.CrossEntropyLoss(ignore_index=TARGET.vocab.stoi['<pad>'])\n",
    "    return enc, dec, loss_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(model_idx, code, lang1, lang2, file_path='./data/en_fa/', file_type='small', device=-1):\n",
    "    config, test_data, test_loader, SOURCE, TARGET = get_model_config(code, lang1, lang2, device=device,\n",
    "                                                                      file_path=file_path, file_type=file_type)\n",
    "    enc, dec, loss_function = build(config, SOURCE, TARGET)\n",
    "    enc.eval()\n",
    "    dec.eval()\n",
    "    \n",
    "    enc_model_path = './data/model/{0}_{1}/{0}-{1}{2}.enc'.format(lang1, lang2, model_idx)\n",
    "    dec_model_path = './data/model/{0}_{1}/{0}-{1}{2}.dec'.format(lang1, lang2, model_idx)\n",
    "    enc.load_state_dict(torch.load(enc_model_path))\n",
    "    dec.load_state_dict(torch.load(dec_model_path))\n",
    "    return enc, dec, loss_function, test_loader, test_data, config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc, dec, loss_function, test_loader, _, config = build_model(model_idx, modelcode_small[model_idx-1], \n",
    "                                                              lang1, lang2, file_path='./data/en_fa/', \n",
    "                                                              file_type='small', device=DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beam Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/IBM/pytorch-seq2seq/blob/master/seq2seq/models/TopKDecoder.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from beam_search import Beam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dec = Decoder(len(TARGET.vocab), config.EMBED, 2*config.HIDDEN, hidden_size2=config.HIDDEN2, \\\n",
    "#                   sos_idx=SOURCE.vocab.stoi['<s>'], method=config.METHOD, USE_CUDA=USE_CUDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, V_d, m_d, n_d, sos_idx=2, num_layers=1, hidden_size2=None, decode_method='greedy',\n",
    "                 method='general', ktop=5, return_weight=True, max_len=15, dropout_rate=0.0, USE_CUDA=True):\n",
    "        super(Decoder, self).__init__()\n",
    "        \"\"\"\n",
    "        vocab_size: V_d\n",
    "        embed_size: m_d\n",
    "        hidden_size: n_d (set this value as 2*n_e)\n",
    "        methods:\n",
    "        - 'dot': dot product between hidden and encoder_outputs\n",
    "        - 'general': encoder_outputs through a linear layer \n",
    "        - 'concat': concat (hidden, encoder_outputs)\n",
    "        - 'paper': concat + tanh\n",
    "        return_weight: return attention weights\n",
    "        \"\"\"\n",
    "        self.V_d = V_d\n",
    "        self.m_d = m_d\n",
    "        self.n_d = n_d\n",
    "        self.sos_idx = sos_idx\n",
    "        self.num_layers = num_layers\n",
    "        self.return_weight = return_weight\n",
    "        self.method = method\n",
    "        self.dec_method = decode_method\n",
    "        self.ktop = ktop\n",
    "        self.use_dropout = False if dropout_rate == 0.0 else True\n",
    "        self.USE_CUDA = USE_CUDA\n",
    "        # attention\n",
    "        self.attention = Attention(hidden_size=n_d, hidden_size2=hidden_size2, method=method)\n",
    "        # embed\n",
    "        self.embed = nn.Embedding(V_d, m_d)\n",
    "        # dropout:\n",
    "        if self.use_dropout:\n",
    "            self.dropout = nn.Dropout(dropout_rate)\n",
    "        # gru(W*[embed, context] + U*[hidden_prev])\n",
    "        # gru: m+n\n",
    "        self.gru = nn.GRU(m_d+n_d, n_d, num_layers, batch_first=True, bidirectional=False)\n",
    "        # linear\n",
    "        self.linear = nn.Linear(2*n_d, V_d)\n",
    "        self.max_len = max_len\n",
    "        \n",
    "        \n",
    "    def start_token(self, batch_size):\n",
    "        sos = torch.LongTensor([self.sos_idx]*batch_size).unsqueeze(1)\n",
    "        if self.USE_CUDA: sos = sos.cuda()\n",
    "        return sos\n",
    "    \n",
    "    def forward(self, hidden, enc_outputs, enc_outputs_lengths=None, max_len=None):\n",
    "        \"\"\"\n",
    "        input:\n",
    "        - hidden(previous hidden): B, 1, n_d \n",
    "        - enc_outputs(source context): B, T_x, n_d\n",
    "        - enc_outputs_lengths: list type\n",
    "        - max_len(targer sentences max len in batch): T_y\n",
    "        \"\"\"\n",
    "        if max_len is None: max_len = self.max_len\n",
    "        \n",
    "        inputs = self.start_token(hidden.size(0)) # (B, 1)\n",
    "        embeded = self.embed(inputs) # (B, 1, m_d)\n",
    "        if self.use_dropout:\n",
    "            embeded = self.dropout(embeded)\n",
    "            \n",
    "        # prepare for whole targer sentence scores\n",
    "        scores = []\n",
    "        attn_weights = []\n",
    "\n",
    "        for i in range(max_len):\n",
    "            # context vector: previous hidden(s{i-1}), encoder_outputs(O_e) > context(c{i}), weights\n",
    "            # - context: (B, 1, n_d)\n",
    "            # - weights: (B, 1, T_x)\n",
    "            context, weights = self.attention(hidden, enc_outputs, enc_outputs_lengths, \n",
    "                                              return_weight=self.return_weight)\n",
    "            attn_weights.append(weights.squeeze(1))\n",
    "            \n",
    "            # concat context & embedding vectors: (B, 1, m_d+n_d)\n",
    "            gru_input = torch.cat([embeded, context], 2)\n",
    "            \n",
    "            # gru((context&embedding), previous hidden)\n",
    "            # output hidden(s{i}): (1, B, n_d)\n",
    "            _, hidden = self.gru(gru_input, hidden.transpose(0, 1))\n",
    "            hidden = hidden.transpose(0, 1)  # change shape to (B, 1, n_d) again\n",
    "            \n",
    "            # concat context and new hidden vectors: (B, 1, 2*n_d)\n",
    "            concated = torch.cat([hidden, context], 2)\n",
    "            \n",
    "            # get score: (B, V_d)\n",
    "            score = self.linear(concated.squeeze(1))\n",
    "            scores.append(score)\n",
    "            \n",
    "            # greedy method\n",
    "            decoded = self.decode_method(score, dec_method=self.dec_method, ktop=self.ktop)  # (B)\n",
    "            embeded = self.embed(decoded).unsqueeze(1) # next input y{i-1} (B, 1, m_d)\n",
    "            if self.use_dropout:\n",
    "                embeded = self.dropout(embeded)\n",
    "\n",
    "        # column-wise concat, reshape!! \n",
    "        # scores = [(B, V_d), (B, V_d), (B, V_d)...] > (B, V_d*max_len)\n",
    "        # attn_weights = [(B, T_x), (B, T_x), (B, T_x)...] > (B*max_len, T_x)\n",
    "        scores = torch.cat(scores, 1)\n",
    "        return scores.view(inputs.size(0)*max_len, -1), torch.cat(attn_weights)\n",
    "\n",
    "    def decode_method(self, score, dec_method='greedy', ktop=5):\n",
    "        prob, decoded = score.max(1)\n",
    "        if dec_method == 'greedy':\n",
    "            return decoded\n",
    "        elif dec_method == 'beam':\n",
    "            pass\n",
    "\n",
    "    def decode(self, hidden, enc_outputs, enc_outputs_lengths, eos_idx=3, max_len=50):\n",
    "        \n",
    "        inputs = self.start_token(hidden.size(0))  # (1, 1)\n",
    "        embeded = self.embed(inputs)  # (1, 1, m_d)\n",
    "        if self.use_dropout:\n",
    "            embeded = self.dropout(embeded)\n",
    "        \n",
    "        decodes = [] \n",
    "        attn_weights = []\n",
    "        decoded = torch.LongTensor([self.sos_idx]).view(1, -1)\n",
    "        \n",
    "        while (decoded.item() != eos_idx):\n",
    "            # context: (1, 1, n_d)\n",
    "            # weights: (1, 1, T_x)\n",
    "            context, weights = self.attention(hidden, enc_outputs, enc_outputs_lengths, \n",
    "                                              return_weight=self.return_weight)\n",
    "            attn_weights.append(weights.squeeze(1))  # (1, T_x)\n",
    "            gru_input = torch.cat([embeded, context], 2)  # (1, 1, m_d+n_d)\n",
    "            _, hidden = self.gru(gru_input, hidden.transpose(0, 1))  # (1, 1, n_d)\n",
    "            hidden = hidden.transpose(0, 1)\n",
    "            concated = torch.cat([hidden, context], 2)  # (1, 1, 2*n_d)\n",
    "            score = self.linear(concated.squeeze(1))  # (1, 2*n_d) -> # (1, V_d)\n",
    "            decoded = score.max(1)[1]  # (1)\n",
    "            decodes.append(decoded)\n",
    "            embeded = self.embed(decoded).unsqueeze(1) # (1, 1, m_d)\n",
    "            if self.use_dropout:\n",
    "                embeded = self.dropout(embeded)\n",
    "            \n",
    "            if len(decodes) >= max_len:\n",
    "                break\n",
    "        \n",
    "        return torch.cat(decodes), torch.cat(attn_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "output, hidden = enc(inputs, lengths.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Decoder' object has no attribute 'dropout'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-8a7eb51f9dc2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0membeded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0membeded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    530\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m--> 532\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Decoder' object has no attribute 'dropout'"
     ]
    }
   ],
   "source": [
    "inputs = dec.start_token(hidden.size(0))\n",
    "embeded = dec.embed(inputs)\n",
    "embeded = dec.dropout(embeded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "beam_search = Beam(5, SOURCE.vocab.stoi['<pad>'], SOURCE.vocab.stoi['<s>'], SOURCE.vocab.stoi['</s>']\n",
    "                   , n_best=1, cuda=USE_CUDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beam_search.advance(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([ 0,  0,  0,  0,  0])]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beam_search.prevKs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([ 2,  1,  1,  1,  1]), tensor([ 4854,   428,  3554,  7799,   869])]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beam_search.nextYs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "beam_idxes = defaultdict(dict)\n",
    "scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_scores, sorted_idxes = score.sort(dim=1, descending=True)\n",
    "ktop_idxes = sorted_idxes[:, :5]\n",
    "ktop_scores = sorted_scores[:, :5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.append(ktop_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "beam_idxes[1]['score'] = ktop_scores\n",
    "beam_idxes[1]['idxes'] = ktop_idxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layer Norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/pytorch/pytorch/issues/4930"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import PackedSequence\n",
    "import torch.nn.functional as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_GRU = StackedGRU(config.EMBED, config.HIDDEN, config.NUM_HIDDEN, bidirectional=True, \n",
    "                         layernorm=False, return_all_hidden=False).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = nn.Embedding(len(SOURCE.vocab), config.EMBED).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeded = embed(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeded, l = pack_padded_sequence(embeded, lengths.tolist(), batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1152, 256]),\n",
       " tensor([ 128,  128,  128,  128,  128,  128,  128,  128,  128]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeded.size(), l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1152, 256])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeded.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "size mismatch, m1: [16 x 5], m2: [512 x 1536] at /pytorch/aten/src/THC/generic/THCTensorMathBlas.cu:249",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-5e3571207503>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstacked_GRU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-0b2e2dd079ce>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, hidden)\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0;31m# forward: idx of time t ~ (0, 1, ..., T-1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0mf_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_layers\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_directions\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0mf_all_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf_last_hidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0;31m# backward:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-0b2e2dd079ce>\u001b[0m in \u001b[0;36m_forward\u001b[0;34m(self, layers, inputs, hidden)\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0moutput_ith_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m                 \u001b[0mhid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m                 \u001b[0moutput_ith_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0moutput_ith_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_ith_layer\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# T, B, H\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-c412c38113cd>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, hidden)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \"\"\"\n\u001b[1;32m     25\u001b[0m         \u001b[0mgi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_ih\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mgh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_hh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mi_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi_n\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mh_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_n\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m    992\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 994\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    995\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: size mismatch, m1: [16 x 5], m2: [512 x 1536] at /pytorch/aten/src/THC/generic/THCTensorMathBlas.cu:249"
     ]
    }
   ],
   "source": [
    "o, h = stacked_GRU(embeded, hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LayerNormGRU(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, batch_first=False, layernorm=False\n",
    "                 bidirectional=False, bias=True, use_cuda=False, return_all_hidden=False), :\n",
    "        super(LayerNormGRU, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.layernorm = layernorm\n",
    "        self.batch_first = batch_first\n",
    "        self.bidrectional = bidirectional\n",
    "        self.return_all_hidden = return_all_hidden\n",
    "        self.num_directions = 2 if self.bidrectional else 1\n",
    "        self.bias = bias\n",
    "        self.gate_num = 3\n",
    "        \n",
    "        \n",
    "    def forward(self, inputs, hidden=None):\n",
    "        \"\"\"\n",
    "        input:\n",
    "        * inputs: seq_len, B, input_size\n",
    "        * hidden: num_layers * num_directions, B, hidden_size\n",
    "        output:\n",
    "        * output: seq_len, B, hidden_size * num_directions\n",
    "        * hidden: num_layers * num_directions, B, hidden_size\n",
    "        \"\"\"\n",
    "        is_packed = isinstance(inputs, PackedSequence)\n",
    "        if is_packed:\n",
    "            inputs, batch_sizes = inputs\n",
    "            max_batch_size = int(batch_sizes[0])\n",
    "        else:\n",
    "            batch_sizes = None\n",
    "            max_batch_size = inputs.size(0) if self.batch_first else inputs.size(1)\n",
    "        \n",
    "        if hidden is None:\n",
    "            hidden = self.init_hidden(inputs, max_batch_size)\n",
    "            \n",
    "        func = stacked_GRU(input_size=self.input_size, \n",
    "                           hidden_size=self.hidden_size, \n",
    "                           num_layers=self.num_layers, \n",
    "                           bidirectional=self.bidrectional, \n",
    "                           layernorm=self.layernorm, \n",
    "                           return_all_hidden=self.return_all_hidden,\n",
    "                           batch_first=self.batch_first,\n",
    "                           batch_sizes=batch_sizes,\n",
    "                           is_packed=is_packed)\n",
    "        \n",
    "        output, hidden = func(inputs, hidden)\n",
    "        \n",
    "        if self.batch_first:\n",
    "            output = output.transpose(0, 1)\n",
    "        \n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self, inpt, max_batch_size):\n",
    "        hx = inpt.new_zeros(self.num_layers * self.num_directions, max_batch_size, self.hidden_size,\n",
    "                            requires_grad=False)\n",
    "        if self.use_cuda:\n",
    "            hx = hx.cuda()\n",
    "        return hx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StackedGRU(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, num_layers, bidirectional=False, layernorm=False, \n",
    "                 return_all_hidden=False, batch_sizes=None, batch_first=False, is_packed=False):\n",
    "        super(StackedGRU, self).__init__()\n",
    "        # to do: add is_packed\n",
    "        self.batch_first = batch_first\n",
    "        self.layernorm = layernorm\n",
    "        self.bidirec = bidirectional\n",
    "        self.return_all_hidden = return_all_hidden\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_directions = 2 if self.bidirec else 1\n",
    "        self.num_layers = num_layers\n",
    "        self.build_layers(input_size, hidden_size)\n",
    "        # packed seq\n",
    "        self.batch_sizes = batch_sizes\n",
    "        self.is_packed = is_packed\n",
    "        \n",
    "    def build_layers(self, input_size, hidden_size):\n",
    "        self.layers = nn.ModuleList()\n",
    "        for _ in range(self.num_layers):\n",
    "            self.layers.append(GRUCell(input_size, hidden_size, layernorm=self.layernorm))\n",
    "            input_size = hidden_size\n",
    "        if self.bidirec:\n",
    "            input_size = self.input_size\n",
    "            self.r_layers = nn.ModuleList()\n",
    "            for _ in range(self.num_layers):\n",
    "                self.r_layers.append(GRUCell(input_size, hidden_size, layernorm=self.layernorm))\n",
    "                input_size = hidden_size\n",
    "    \n",
    "    \n",
    "    def forward(self, inputs, hidden, batch_sizes=None):\n",
    "        \"\"\"\n",
    "        * input:\n",
    "        inputs: 'tensor(T, B, D)' if packed, 'tensor(T*B, D)'\n",
    "        hidden: 'tensor(num_layers * num_directions, B, H)'\n",
    "        \n",
    "        * return:\n",
    "        output: 'tensor(num_layers, T, B, 2H)' if return_all_hiddens else last layer 'tensor(T, B, 2H)'\n",
    "        hidden 'tensor(num_layers*num_directions, B, H)'\n",
    "        \"\"\"\n",
    "        if self.bidirec:\n",
    "            # output (num_layers, T, B, 2H)\n",
    "            # last_hidden (num_layers*num_directions, B, H)\n",
    "            # forward: idx of time t ~ (0, 1, ..., T-1)            \n",
    "            f_idx = [i for i in range(self.num_layers * self.num_directions) if i % 2 == 0]\n",
    "            f_all_outputs, f_last_hidden = self._forward(self.layers, inputs, hidden[f_idx, :])\n",
    "            \n",
    "            # backward: \n",
    "            r_inputs = self._flip(inputs, 0)  # (T, B, H) idx of time t ~ (T-1, ... , 0)\n",
    "            b_idx = [i for i in range(self.num_layers * self.num_directions) if i % 2 != 0]\n",
    "            b_all_outputs, b_last_hidden = self._forward(self.r_layers, r_inputs, hidden[b_idx, :])\n",
    "            \n",
    "            # concate layers\n",
    "            # f: hidden[T-1], b: hidden[0]\n",
    "            output = torch.cat([f_all_outputs, b_all_outputs], -1)\n",
    "            idx = [int(i/self.num_directions) if i % 2 == 0 else \\\n",
    "                   i + int(((self.num_layers * self.num_directions) - i) / 2) \\\n",
    "                   for i in range(self.num_layers * self.num_directions) ]\n",
    "            hidden = torch.cat([f_last_hidden, b_last_hidden])[idx, :]\n",
    "\n",
    "            if self.return_all_hidden:\n",
    "                return output, hidden\n",
    "            return output[-1], hidden\n",
    "            \n",
    "        else:\n",
    "            f_all_outputs, f_last_hidden = self._forward(self.layers, inputs, hidden)\n",
    "            if self.return_all_hidden:\n",
    "                return f_all_outputs, f_last_hidden\n",
    "            return f_all_outputs[-1], f_last_hidden\n",
    "\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        # init_hidden\n",
    "        hidden = torch.zeros((self.num_layers*self.num_directions, batch_size, self.hidden_size))\n",
    "        return hidden\n",
    "\n",
    "    def _forward(self, layers, inputs, hidden, batch_sizes=None):\n",
    "        \"\"\"\n",
    "        * input:\n",
    "        layers: nn.ModuleList for one direction layers\n",
    "        inp: T, B, D\n",
    "        hid: num_layers, B, H (init hidden)\n",
    "        \n",
    "        * return:\n",
    "        all_outputs: all layers a forward or backward layer\n",
    "        tensor(num_layers, T, B, H)\n",
    "        last_hidden: \n",
    "        tensor(num_layers, B, H)\n",
    "        \"\"\"\n",
    "        # todo: add is_packed\n",
    "        assert isinstance(layers, nn.ModuleList)\n",
    "        inp = inputs\n",
    "        \n",
    "        all_outputs = []\n",
    "        for l_idx, layer in enumerate(layers):\n",
    "            hid = hidden.chunk(3, 0)[l_idx].squeeze(0)  # init hidden: 1, B, H --> B, H\n",
    "            output_ith_layer = []\n",
    "            for t in range(inp.size(0)):\n",
    "                hid = layer(inp[t], hid)\n",
    "                output_ith_layer.append(hid)\n",
    "            output_ith_layer = torch.stack(output_ith_layer)  # T, B, H\n",
    "            inp = output_ith_layer \n",
    "            all_outputs.append(output_ith_layer)\n",
    "        \n",
    "        last_hidden = torch.stack([out[-1] for out in all_outputs]) # num_layer, B, H\n",
    "        return torch.stack(all_outputs), last_hidden\n",
    "    \n",
    "    \n",
    "    def _flip(self, x, dim):\n",
    "        \"\"\"\n",
    "        https://discuss.pytorch.org/t/optimizing-diagonal-stripe-code/17777/16\n",
    "        \"\"\"\n",
    "        indices = [slice(None)] * x.dim()\n",
    "        indices[dim] = torch.arange(x.size(dim) - 1, -1, -1,\n",
    "                                    dtype=torch.long, device=x.device)\n",
    "        return x[tuple(indices)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUCell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, bias=True, layernorm=False, gate_num=3):\n",
    "        super(GRUCell, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.bias = bias\n",
    "        self.hidden_size = hidden_size\n",
    "        self.layernorm = layernorm\n",
    "        self.gate_num = gate_num\n",
    "        \n",
    "        self.weight_ih = nn.Linear(input_size, gate_num*hidden_size, bias=bias)\n",
    "        self.weight_hh = nn.Linear(hidden_size, gate_num*hidden_size, bias=bias)\n",
    "        \n",
    "        self.lm_r = nn.LayerNorm(hidden_size)\n",
    "        self.lm_i = nn.LayerNorm(hidden_size)\n",
    "        self.lm_n = nn.LayerNorm(hidden_size)\n",
    "        \n",
    "    def forward(self, inputs, hidden):\n",
    "        \"\"\"\n",
    "        inputs:\n",
    "        * inputs: B, input_size\n",
    "        * hidden: B, hidden_size\n",
    "        output:\n",
    "        * hy: B, hidden_size\n",
    "        \"\"\"\n",
    "        gi = self.weight_ih(inputs)\n",
    "        gh = self.weight_hh(hidden)\n",
    "        i_r, i_i, i_n = gi.chunk(3, 1)\n",
    "        h_r, h_i, h_n = gh.chunk(3, 1)\n",
    "        \n",
    "        a_r = i_r + h_r\n",
    "        a_i = i_i + h_i\n",
    "        if self.layernorm:\n",
    "            a_r = self.lm_r(a_r)\n",
    "            a_i = self.lm_i(a_i)\n",
    "            \n",
    "        resetgate = F.sigmoid(a_r)\n",
    "        inputgate = F.sigmoid(a_i)\n",
    "        \n",
    "        a_n = i_n + resetgate * h_n\n",
    "        if self.layernorm:\n",
    "            a_n = self.lm_n(a_n)\n",
    "            \n",
    "        newgate = F.tanh(a_n)\n",
    "        hy = newgate + inputgate * (hidden - newgate)\n",
    "        return hy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
